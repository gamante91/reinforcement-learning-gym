{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "openAI-gym-taxi-v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gamante91/reinforcement-learning-gym/blob/master/Taxi_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "2du7zL0PGQpM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import gym\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sys\n",
        "from time import sleep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qJDWNICKQfMn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "constants and free functions\n",
        "'''\n",
        "epsilon_max = 0.95\n",
        "\n",
        "clear = lambda : sys.stdout.flush()\n",
        "\n",
        "def select_epsilon_greedy_action(Q_s, nA, epsilon):\n",
        "  return np.argmax(Q_s) if np.random.sample() < epsilon else np.random.choice(nA)\n",
        "\n",
        "def select_greedy_action(Q_s):\n",
        "  return np.argmax(Q_s)\n",
        "\n",
        "def render(env, info):\n",
        "    clear()\n",
        "    env.render()\n",
        "\n",
        "    if 'state' in info:\n",
        "        print(\"state:\", info['state'])\n",
        "    if 'action' in info:\n",
        "        print(\"action:\", info['action'])\n",
        "    if 'reward' in info:\n",
        "        print(\"reward:\", info['reward'])\n",
        "        if 'done' in info and info['done']:\n",
        "          print(\"game ended\")\n",
        "          print(\"you won! :)\") if info['reward'] > 0 else print(\"you lost! :(\")\n",
        "    \n",
        "    sleep(0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5echn6MoGbrr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "  \n",
        "  def __init__(self, nA):\n",
        "    ''' \n",
        "    agent's constructor \n",
        "    '''\n",
        "    self.nA = nA\n",
        "    self.Q = defaultdict(lambda: np.zeros(self.nA))\n",
        "    \n",
        "  def train(self, env, num_episodes, alpha, gamma, epsilon):\n",
        "    '''\n",
        "    trains the agent over a fixed number of episodes using Q-learning\n",
        "    '''\n",
        "    rewards = []\n",
        "    max_reward = -math.inf\n",
        "    \n",
        "    for i_episode in range(1, num_episodes+1):\n",
        "      state = env.reset()\n",
        "      done = False\n",
        "      tot_reward = 0\n",
        "      eps = max(epsilon * i_episode, epsilon_max)\n",
        "      \n",
        "      while not done:\n",
        "        action = select_epsilon_greedy_action(self.Q[state], self.nA, eps)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        tot_reward += reward\n",
        "        \n",
        "        '''\n",
        "        updated internal Q table using Q-learning update rule\n",
        "        '''\n",
        "        self.Q[state][action] += alpha * (reward + gamma * self.Q[next_state][np.argmax(self.Q[next_state])] - + self.Q[state][action])\n",
        "        state = next_state\n",
        "        \n",
        "      if (i_episode % 100 == 0):\n",
        "        print(\"episode:\", i_episode, \"reward:\", tot_reward, \", best reward so far:\", max_reward)\n",
        "      rewards.append(tot_reward)\n",
        "      max_reward = max(max_reward, tot_reward)\n",
        "      clear()\n",
        "      \n",
        "  def play(self, env, showDisplay):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    tot_reward = 0 \n",
        "    \n",
        "    while not done:\n",
        "      action = select_greedy_action(self.Q[state])\n",
        "      state, reward, done, _ = env.step(action)\n",
        "      tot_reward += reward\n",
        "      \n",
        "      info = {'state': state, 'action': action, 'reward': reward, 'done': done}\n",
        "      \n",
        "      if (showDisplay):\n",
        "        render(env, info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dSzYgYHWGeJS",
        "colab_type": "code",
        "outputId": "760dae37-d5c0-4f33-b4df-57d736ac844d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        }
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('Taxi-v2')\n",
        "\n",
        "agent = Agent(env.action_space.n)\n",
        "agent.train(env, 20000, 0.1, 0.9, 0.1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 100 reward: -317 , best reward so far: 1\n",
            "episode: 200 reward: -85 , best reward so far: 11\n",
            "episode: 300 reward: -107 , best reward so far: 12\n",
            "episode: 400 reward: 9 , best reward so far: 12\n",
            "episode: 500 reward: -55 , best reward so far: 15\n",
            "episode: 600 reward: -60 , best reward so far: 15\n",
            "episode: 700 reward: 5 , best reward so far: 15\n",
            "episode: 800 reward: 9 , best reward so far: 15\n",
            "episode: 900 reward: 11 , best reward so far: 15\n",
            "episode: 1000 reward: -118 , best reward so far: 15\n",
            "episode: 1100 reward: 12 , best reward so far: 15\n",
            "episode: 1200 reward: 6 , best reward so far: 15\n",
            "episode: 1300 reward: 7 , best reward so far: 15\n",
            "episode: 1400 reward: 12 , best reward so far: 15\n",
            "episode: 1500 reward: 14 , best reward so far: 15\n",
            "episode: 1600 reward: 8 , best reward so far: 15\n",
            "episode: 1700 reward: 3 , best reward so far: 15\n",
            "episode: 1800 reward: 12 , best reward so far: 15\n",
            "episode: 1900 reward: 7 , best reward so far: 15\n",
            "episode: 2000 reward: 8 , best reward so far: 15\n",
            "episode: 2100 reward: 9 , best reward so far: 15\n",
            "episode: 2200 reward: 8 , best reward so far: 15\n",
            "episode: 2300 reward: 11 , best reward so far: 15\n",
            "episode: 2400 reward: 5 , best reward so far: 15\n",
            "episode: 2500 reward: 8 , best reward so far: 15\n",
            "episode: 2600 reward: 8 , best reward so far: 15\n",
            "episode: 2700 reward: 15 , best reward so far: 15\n",
            "episode: 2800 reward: 6 , best reward so far: 15\n",
            "episode: 2900 reward: 8 , best reward so far: 15\n",
            "episode: 3000 reward: 9 , best reward so far: 15\n",
            "episode: 3100 reward: 9 , best reward so far: 15\n",
            "episode: 3200 reward: 5 , best reward so far: 15\n",
            "episode: 3300 reward: 7 , best reward so far: 15\n",
            "episode: 3400 reward: 10 , best reward so far: 15\n",
            "episode: 3500 reward: 12 , best reward so far: 15\n",
            "episode: 3600 reward: 8 , best reward so far: 15\n",
            "episode: 3700 reward: 8 , best reward so far: 15\n",
            "episode: 3800 reward: 7 , best reward so far: 15\n",
            "episode: 3900 reward: 1 , best reward so far: 15\n",
            "episode: 4000 reward: 6 , best reward so far: 15\n",
            "episode: 4100 reward: 10 , best reward so far: 15\n",
            "episode: 4200 reward: 7 , best reward so far: 15\n",
            "episode: 4300 reward: 9 , best reward so far: 15\n",
            "episode: 4400 reward: 11 , best reward so far: 15\n",
            "episode: 4500 reward: 6 , best reward so far: 15\n",
            "episode: 4600 reward: 9 , best reward so far: 15\n",
            "episode: 4700 reward: 6 , best reward so far: 15\n",
            "episode: 4800 reward: 7 , best reward so far: 15\n",
            "episode: 4900 reward: 7 , best reward so far: 15\n",
            "episode: 5000 reward: 9 , best reward so far: 15\n",
            "episode: 5100 reward: 5 , best reward so far: 15\n",
            "episode: 5200 reward: 12 , best reward so far: 15\n",
            "episode: 5300 reward: 7 , best reward so far: 15\n",
            "episode: 5400 reward: 9 , best reward so far: 15\n",
            "episode: 5500 reward: 13 , best reward so far: 15\n",
            "episode: 5600 reward: 10 , best reward so far: 15\n",
            "episode: 5700 reward: 5 , best reward so far: 15\n",
            "episode: 5800 reward: 8 , best reward so far: 15\n",
            "episode: 5900 reward: 9 , best reward so far: 15\n",
            "episode: 6000 reward: 5 , best reward so far: 15\n",
            "episode: 6100 reward: 3 , best reward so far: 15\n",
            "episode: 6200 reward: 4 , best reward so far: 15\n",
            "episode: 6300 reward: 7 , best reward so far: 15\n",
            "episode: 6400 reward: 5 , best reward so far: 15\n",
            "episode: 6500 reward: 8 , best reward so far: 15\n",
            "episode: 6600 reward: 7 , best reward so far: 15\n",
            "episode: 6700 reward: 5 , best reward so far: 15\n",
            "episode: 6800 reward: 11 , best reward so far: 15\n",
            "episode: 6900 reward: 8 , best reward so far: 15\n",
            "episode: 7000 reward: 8 , best reward so far: 15\n",
            "episode: 7100 reward: 8 , best reward so far: 15\n",
            "episode: 7200 reward: 6 , best reward so far: 15\n",
            "episode: 7300 reward: 12 , best reward so far: 15\n",
            "episode: 7400 reward: 4 , best reward so far: 15\n",
            "episode: 7500 reward: 5 , best reward so far: 15\n",
            "episode: 7600 reward: 9 , best reward so far: 15\n",
            "episode: 7700 reward: 8 , best reward so far: 15\n",
            "episode: 7800 reward: 7 , best reward so far: 15\n",
            "episode: 7900 reward: 9 , best reward so far: 15\n",
            "episode: 8000 reward: 8 , best reward so far: 15\n",
            "episode: 8100 reward: 9 , best reward so far: 15\n",
            "episode: 8200 reward: 11 , best reward so far: 15\n",
            "episode: 8300 reward: 10 , best reward so far: 15\n",
            "episode: 8400 reward: 9 , best reward so far: 15\n",
            "episode: 8500 reward: 11 , best reward so far: 15\n",
            "episode: 8600 reward: 8 , best reward so far: 15\n",
            "episode: 8700 reward: 9 , best reward so far: 15\n",
            "episode: 8800 reward: 4 , best reward so far: 15\n",
            "episode: 8900 reward: 12 , best reward so far: 15\n",
            "episode: 9000 reward: 5 , best reward so far: 15\n",
            "episode: 9100 reward: 9 , best reward so far: 15\n",
            "episode: 9200 reward: 9 , best reward so far: 15\n",
            "episode: 9300 reward: 8 , best reward so far: 15\n",
            "episode: 9400 reward: 5 , best reward so far: 15\n",
            "episode: 9500 reward: 12 , best reward so far: 15\n",
            "episode: 9600 reward: 8 , best reward so far: 15\n",
            "episode: 9700 reward: 5 , best reward so far: 15\n",
            "episode: 9800 reward: 9 , best reward so far: 15\n",
            "episode: 9900 reward: 7 , best reward so far: 15\n",
            "episode: 10000 reward: 13 , best reward so far: 15\n",
            "episode: 10100 reward: 12 , best reward so far: 15\n",
            "episode: 10200 reward: 10 , best reward so far: 15\n",
            "episode: 10300 reward: 10 , best reward so far: 15\n",
            "episode: 10400 reward: 8 , best reward so far: 15\n",
            "episode: 10500 reward: 8 , best reward so far: 15\n",
            "episode: 10600 reward: 4 , best reward so far: 15\n",
            "episode: 10700 reward: 6 , best reward so far: 15\n",
            "episode: 10800 reward: 9 , best reward so far: 15\n",
            "episode: 10900 reward: 8 , best reward so far: 15\n",
            "episode: 11000 reward: 5 , best reward so far: 15\n",
            "episode: 11100 reward: 7 , best reward so far: 15\n",
            "episode: 11200 reward: 7 , best reward so far: 15\n",
            "episode: 11300 reward: 8 , best reward so far: 15\n",
            "episode: 11400 reward: 6 , best reward so far: 15\n",
            "episode: 11500 reward: 12 , best reward so far: 15\n",
            "episode: 11600 reward: 4 , best reward so far: 15\n",
            "episode: 11700 reward: 11 , best reward so far: 15\n",
            "episode: 11800 reward: 10 , best reward so far: 15\n",
            "episode: 11900 reward: 9 , best reward so far: 15\n",
            "episode: 12000 reward: 6 , best reward so far: 15\n",
            "episode: 12100 reward: 4 , best reward so far: 15\n",
            "episode: 12200 reward: 5 , best reward so far: 15\n",
            "episode: 12300 reward: 11 , best reward so far: 15\n",
            "episode: 12400 reward: 14 , best reward so far: 15\n",
            "episode: 12500 reward: 12 , best reward so far: 15\n",
            "episode: 12600 reward: 9 , best reward so far: 15\n",
            "episode: 12700 reward: 9 , best reward so far: 15\n",
            "episode: 12800 reward: 9 , best reward so far: 15\n",
            "episode: 12900 reward: 8 , best reward so far: 15\n",
            "episode: 13000 reward: 15 , best reward so far: 15\n",
            "episode: 13100 reward: 13 , best reward so far: 15\n",
            "episode: 13200 reward: 9 , best reward so far: 15\n",
            "episode: 13300 reward: 7 , best reward so far: 15\n",
            "episode: 13400 reward: 11 , best reward so far: 15\n",
            "episode: 13500 reward: 10 , best reward so far: 15\n",
            "episode: 13600 reward: 11 , best reward so far: 15\n",
            "episode: 13700 reward: 15 , best reward so far: 15\n",
            "episode: 13800 reward: 6 , best reward so far: 15\n",
            "episode: 13900 reward: 8 , best reward so far: 15\n",
            "episode: 14000 reward: 8 , best reward so far: 15\n",
            "episode: 14100 reward: 8 , best reward so far: 15\n",
            "episode: 14200 reward: 10 , best reward so far: 15\n",
            "episode: 14300 reward: 8 , best reward so far: 15\n",
            "episode: 14400 reward: 9 , best reward so far: 15\n",
            "episode: 14500 reward: 9 , best reward so far: 15\n",
            "episode: 14600 reward: 5 , best reward so far: 15\n",
            "episode: 14700 reward: 8 , best reward so far: 15\n",
            "episode: 14800 reward: 8 , best reward so far: 15\n",
            "episode: 14900 reward: 4 , best reward so far: 15\n",
            "episode: 15000 reward: 8 , best reward so far: 15\n",
            "episode: 15100 reward: 9 , best reward so far: 15\n",
            "episode: 15200 reward: 11 , best reward so far: 15\n",
            "episode: 15300 reward: 6 , best reward so far: 15\n",
            "episode: 15400 reward: 4 , best reward so far: 15\n",
            "episode: 15500 reward: 11 , best reward so far: 15\n",
            "episode: 15600 reward: 7 , best reward so far: 15\n",
            "episode: 15700 reward: 5 , best reward so far: 15\n",
            "episode: 15800 reward: 7 , best reward so far: 15\n",
            "episode: 15900 reward: 8 , best reward so far: 15\n",
            "episode: 16000 reward: 8 , best reward so far: 15\n",
            "episode: 16100 reward: 14 , best reward so far: 15\n",
            "episode: 16200 reward: 14 , best reward so far: 15\n",
            "episode: 16300 reward: 10 , best reward so far: 15\n",
            "episode: 16400 reward: 13 , best reward so far: 15\n",
            "episode: 16500 reward: 7 , best reward so far: 15\n",
            "episode: 16600 reward: 7 , best reward so far: 15\n",
            "episode: 16700 reward: 10 , best reward so far: 15\n",
            "episode: 16800 reward: 11 , best reward so far: 15\n",
            "episode: 16900 reward: 7 , best reward so far: 15\n",
            "episode: 17000 reward: 5 , best reward so far: 15\n",
            "episode: 17100 reward: 6 , best reward so far: 15\n",
            "episode: 17200 reward: 8 , best reward so far: 15\n",
            "episode: 17300 reward: 4 , best reward so far: 15\n",
            "episode: 17400 reward: 6 , best reward so far: 15\n",
            "episode: 17500 reward: 13 , best reward so far: 15\n",
            "episode: 17600 reward: 13 , best reward so far: 15\n",
            "episode: 17700 reward: 8 , best reward so far: 15\n",
            "episode: 17800 reward: 10 , best reward so far: 15\n",
            "episode: 17900 reward: 14 , best reward so far: 15\n",
            "episode: 18000 reward: 7 , best reward so far: 15\n",
            "episode: 18100 reward: 4 , best reward so far: 15\n",
            "episode: 18200 reward: 8 , best reward so far: 15\n",
            "episode: 18300 reward: 8 , best reward so far: 15\n",
            "episode: 18400 reward: 7 , best reward so far: 15\n",
            "episode: 18500 reward: 8 , best reward so far: 15\n",
            "episode: 18600 reward: 4 , best reward so far: 15\n",
            "episode: 18700 reward: 6 , best reward so far: 15\n",
            "episode: 18800 reward: 7 , best reward so far: 15\n",
            "episode: 18900 reward: 10 , best reward so far: 15\n",
            "episode: 19000 reward: 6 , best reward so far: 15\n",
            "episode: 19100 reward: 8 , best reward so far: 15\n",
            "episode: 19200 reward: 10 , best reward so far: 15\n",
            "episode: 19300 reward: 9 , best reward so far: 15\n",
            "episode: 19400 reward: 10 , best reward so far: 15\n",
            "episode: 19500 reward: 8 , best reward so far: 15\n",
            "episode: 19600 reward: 6 , best reward so far: 15\n",
            "episode: 19700 reward: 6 , best reward so far: 15\n",
            "episode: 19800 reward: 8 , best reward so far: 15\n",
            "episode: 19900 reward: 6 , best reward so far: 15\n",
            "episode: 20000 reward: 14 , best reward so far: 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z_dg5ZFyfBaP",
        "colab_type": "code",
        "outputId": "8714d5df-047e-4f4e-fcac-9821a93ad157",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        }
      },
      "cell_type": "code",
      "source": [
        "agent.play(env, True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (North)\n",
            "state: 1\n",
            "action: 1\n",
            "reward: -1\n",
            "+---------+\n",
            "|\u001b[42mR\u001b[0m: | : :\u001b[35mG\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Pickup)\n",
            "state: 17\n",
            "action: 4\n",
            "reward: -1\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "|\u001b[42m_\u001b[0m: : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (South)\n",
            "state: 117\n",
            "action: 0\n",
            "reward: -1\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| :\u001b[42m_\u001b[0m: : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (East)\n",
            "state: 137\n",
            "action: 2\n",
            "reward: -1\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : :\u001b[42m_\u001b[0m: : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (East)\n",
            "state: 157\n",
            "action: 2\n",
            "reward: -1\n",
            "+---------+\n",
            "|R: | : :\u001b[35mG\u001b[0m|\n",
            "| : : :\u001b[42m_\u001b[0m: |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (East)\n",
            "state: 177\n",
            "action: 2\n",
            "reward: -1\n",
            "+---------+\n",
            "|R: | :\u001b[42m_\u001b[0m:\u001b[35mG\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (North)\n",
            "state: 77\n",
            "action: 1\n",
            "reward: -1\n",
            "+---------+\n",
            "|R: | : :\u001b[35m\u001b[42mG\u001b[0m\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (East)\n",
            "state: 97\n",
            "action: 2\n",
            "reward: -1\n",
            "+---------+\n",
            "|R: | : :\u001b[35m\u001b[34;1m\u001b[43mG\u001b[0m\u001b[0m\u001b[0m|\n",
            "| : : : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "state: 85\n",
            "action: 5\n",
            "reward: 20\n",
            "game ended\n",
            "you won! :)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}